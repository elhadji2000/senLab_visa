from flask import Flask, request, Response
from flask_cors import CORS
import ollama
import json

app = Flask(__name__)
CORS(app)

# Prompt syst√®me global
system_prompt = (
    "Tu es un assistant sp√©cialis√© uniquement dans les sciences STEM "
    "(Math√©matiques, Physique, Chimie, Informatique, Biologie). "
    "Ne r√©ponds jamais √† des questions hors STEM. "
    "Limite strictement chaque r√©ponse √† un maximum de 3 phrases. "
    "Donne des explications claires pour √©l√®ves du secondaire au S√©n√©gal."
)

# ==============================
# Endpoint /chat (streaming)
# ==============================
@app.route("/chat", methods=["POST"])
def chat_stream():
    data = request.json
    question = data.get("question", "")

    def generate():
        try:
            stream = ollama.chat(
                model="llama3.2:3b",  # üî• version l√©g√®re
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question}
                ],
                stream=True
            )

            for chunk in stream:
                if "message" in chunk and "content" in chunk["message"]:
                    token = chunk["message"]["content"]
                    yield f"data: {json.dumps({'token': token})}\n\n"

            yield "data: [DONE]\n\n"

        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"

    return Response(generate(), mimetype="text/event-stream")


if __name__ == "__main__":
    app.run(port=5050, debug=True, threaded=True)
